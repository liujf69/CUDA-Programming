# 并行性
    在应用程序中有两种基本的并行类型: 任务并行和数据并行。
    任务并行: 许多任务或函数可以独立地、大规模地并行执行。
    数据并行: 同时并行处理许多数据。
## 数据划分
    数据并行对数据划分: 块划分和周期划分。
    块划分: 一组连续的数据被划分到一个块内，每个数据块以任意次序被安排给一个线程，线程通常在同一时间只处理一个数据块。
    周期划分: 少量数据被划分到一个块内，相邻的线程处理相邻的数据块; 每个线程可以处理多个数据块，每次处理新数据块时需要跳过和现有线程一样多的数据块。

# 计算机架构
    弗林分类法根据指令和数据进入CPU的方式，将计算机架构划分为: 单指令单数据(SISD)，单指令多数据(SIMD)，多指令单数据(MISD)，多指令单数据(MIMD)。
## 计算机架构的目的
    1. 降低延迟: 延迟是一个操作从开始到完成所需要的时间，单位一般为微妙;
    2. 提高带宽: 带宽是单位时间内可处理的数据量，一般表示为MB/s或GB/s;
    3. 提高吞吐量: 吞吐量时单位时间内成功处理的运算数量，一般用gflops(每秒十亿次的浮点运算数量)表示;

# 异构计算
    异构: CPU和GPU是两个独立的处理器，其通过单个计算节点中的PCIE总线相连; 由CPU和GPU组成的计算系统就是典型的异构系统。
    异构架构中，CPU所在的位置称为主机端(host)，GPU所在的位置称为设备端(device)。
    一个异构应用包括主机代码和设备代码，主机代码在CPU上运行，设备代码在GPU上运行。
## 计算选择
    CPU计算适合处理控制密集型任务，GPU计算适合处理包含数据并行的计算密集任务;
    当一个问题拥有较小的数据规模、复杂的控制逻辑或较少的并行性时，适合选择CPU来处理;
    当一个问题包含大规模待处理数据并表现出大量的数据并行性，适合选择GPU来处理。

## API划分
    CUDA提供了两层API来管理GPU的设备和组织线程: CUDA驱动API和CUDA运行时API;
    驱动API是一种低级API，较难用于编程; 运行时API是一种高级API，其在驱动API的基础上实现;
    驱动API和运行时API没有明显的性能差异，并且两者互相排斥，不能同时使用，一般编程中使用运行时API。

# 代码示例
## 编译运行
    nvcc -arch sm_20 hello.cu -o hello
    or
    mkdir build && cd build
    cmake ..
    make
    ./main
## 代码结果
<div align=center>
<img src="https://github.com/liujf69/CUDA-Programming/blob/main/%E5%BC%82%E6%9E%84%E8%AE%A1%E7%AE%97%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/Hello.png"/>
</div>
